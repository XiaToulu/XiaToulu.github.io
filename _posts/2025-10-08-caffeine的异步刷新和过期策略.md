好的，Caffeine 的异步刷新和过期策略是其作为高性能现代缓存库的核心特性之一，它们共同协作，在保证数据新鲜度的同时，避免了尖锐的缓存失效问题。

下面我们详细拆解这两个概念，并说明它们如何协同工作。

---

### 1. 过期策略

过期策略决定了缓存条目何时会因“太老”而被**自动移除**。Caffeine 提供了三种主要的过期方式：

#### a. 基于写入时间的过期

```java
// 在写入后固定时间过期
LoadingCache<Key, Graph> cache = Caffeine.newBuilder()
    .expireAfterWrite(10, TimeUnit.MINUTES)
    .build(key -> createExpensiveGraph(key));

// 在写入后或最后一次访问后（根据以下策略）固定时间过期
LoadingCache<Key, Graph> cache = Caffeine.newBuilder()
    .expireAfterAccess(10, TimeUnit.MINUTES)
    .build(key -> createExpensiveGraph(key));
```

*   `expireAfterWrite(duration)`:
    *   **这是最常用、最严格的策略。**
    *   无论这个缓存项被访问多少次，只要超过设定的时间，就会被自动移除。
    *   **优点**：能保证数据在指定时间后一定是最新的（下次请求会触发同步加载）。
    *   **适用场景**：对数据一致性要求较高的场景，如配置信息、元数据等。

*   `expireAfterAccess(duration)`:
    *   一个缓存项在最后一次被**访问**（读或写）之后，如果超过设定时间没有被再次访问，就会被移除。
    *   **优点**：对于热点数据非常友好，只要一直被访问，就会长期留在缓存中。
    *   **缺点**：无法保证数据的新鲜度，可能缓存了很久的旧数据。
    *   **适用场景**：用于容易被大量请求的、对一致性要求不高的热点数据，如用户会话。

#### b. 基于自定义变量的过期

```java
// 根据条目的创建时间、更新时间为每个条目指定不同的过期时间
LoadingCache<Key, Graph> cache = Caffeine.newBuilder()
    .expireAfter(new Expiry<Key, Graph>() {
      @Override
      public long expireAfterCreate(Key key, Graph graph, long currentTime) {
        // 根据graph中的某个属性，比如有效期至，返回剩余的存活时间
        return graph.getExpireTimestamp() - currentTime;
      }
      @Override
      public long expireAfterUpdate(Key key, Graph graph, long currentTime, long currentDuration) {
        return currentDuration; // 更新后不改变过期时间
      }
      @Override
      public long expireAfterRead(Key key, Graph graph, long currentTime, long currentDuration) {
        return currentDuration; // 读取后不改变过期时间
      }
    })
    .build(key -> createExpensiveGraph(key));
```

*   **功能最强大**，允许你为每个缓存条目指定独立的、动态的过期时间。
*   **适用场景**：例如，从数据库加载的数据本身带有 `TTL` 字段，或者不同类型的对象需要不同的缓存时长。

---

### 2. 异步刷新

异步刷新是 Caffeine 一个非常强大的特性，它**与过期不同**，其目的不是为了移除数据，而是为了**在数据即将过期时，自动、异步地重新加载最新数据**。

#### 核心机制

```java
LoadingCache<Key, Graph> cache = Caffeine.newBuilder()
    // 1. 设置刷新时间，必须和build方法配合使用（有隐形条件，写入后，如果有访问才会1分钟后刷新）
    .refreshAfterWrite(1, TimeUnit.MINUTES)
    // 2. 设置一个过期时间作为兜底，避免永远不刷新
    .expireAfterWrite(10, TimeUnit.MINUTES)
    // 3. 提供同步的加载函数，用于刷新时调用
    .build(key -> createExpensiveGraph(key));
```

**工作原理：**

1.  **触发条件**：当一个缓存项被访问，并且自从它被**写入或最后一次刷新**后，时间已经超过了 `refreshAfterWrite` 设定的时长。
2.  **异步行为**：Caffeine 会立即返回**旧的缓存值**给调用者，不会阻塞请求。
3.  **后台加载**：同时，Caffeine 会异步地调用你提供的 `CacheLoader`（也就是 `build` 方法中的 lambda 表达式）去加载最新的数据。
4.  **更新缓存**：当新数据加载成功后，它会自动替换掉缓存中的旧值。
5.  **并发控制**：如果在刷新过程中，有多个请求同时访问同一个 key，只有**第一个请求**会触发刷新，其他请求仍然直接获取旧值，避免了缓存击穿。

#### 为什么异步刷新如此重要？

它完美地解决了 **“尖锐的缓存失效”** 问题：

*   **没有异步刷新**：假设一个热门 key 在 10 分钟时过期。在第 10 分 01 秒，突然有 1000 个请求同时到达，发现缓存失效，这 1000 个请求会全部涌向数据库，可能导致数据库瞬间压力过大而崩溃。
*   **有异步刷新**：设置 `refreshAfterWrite(1, TimeUnit.MINUTES)`。在第 1 分钟之后，第一个到达的请求会触发异步刷新，并立即返回旧数据。后续的 999 个请求在刷新完成前，拿到的也都是旧数据，**没有任何一个请求会被阻塞或直接访问数据库**。缓存总是在“不知不觉”中更新。

---

### 3. 过期与刷新的协同工作模式

在实际应用中，我们通常会将 `refreshAfterWrite` 和 `expireAfterWrite` 组合使用，形成一个多层次的保护策略。

**典型配置：**

```java
LoadingCache<Key, Graph> cache = Caffeine.newBuilder()
    .maximumSize(10_000)
    // 组合策略：刷新 + 过期
    .refreshAfterWrite(1, TimeUnit.MINUTES) // 1分钟后，访问则触发异步刷新
    .expireAfterWrite(10, TimeUnit.MINUTES) // 10分钟后，强制过期移除
    .build(key -> createExpensiveGraph(key));
```

**协同工作流程：**

1.  **0 ~ 1分钟**：所有请求直接从缓存中返回数据，性能最佳。
2.  **1 ~ 10分钟**：
    *   当一个请求访问缓存时，Caffeine 会检查是否满足刷新条件（写入后超过1分钟）。
    *   如果满足，则**触发异步刷新**，并**立即返回当前（可能稍旧）的数据**。
    *   在这个时间段内，用户感知不到延迟，数据也基本保持较新的状态。
3.  **10分钟后**：
    *   缓存项因为 `expireAfterWrite` 而**过期**，会被自动移除。
    *   `expireAfterWrite` 在这里扮演了一个**兜底角色**。如果在这10分钟内，某个 key 一直**没有被访问**，那么异步刷新就不会被触发。如果没有这个过期时间，这个 key 就会永远以旧数据的形式留在缓存里。过期机制确保了即使没有访问，最旧的数据也会被清理掉，下次访问时一定会同步加载最新数据。

### 总结

| 特性                    | 目的                                     | 行为                                                 | 对性能的影响                                     |
| :---------------------- | :--------------------------------------- | :--------------------------------------------------- | :----------------------------------------------- |
| **`expireAfterWrite`**  | **保证数据新鲜度上限**，强制移除旧数据。 | 同步，到期移除。下次请求**同步加载**（可能阻塞）。   | 可能导致缓存失效瞬间的数据库压力（缓存击穿）。   |
| **`refreshAfterWrite`** | **在后台保持数据新鲜**，避免尖锐失效。   | 异步，到期后下次访问触发**后台加载**。立即返回旧值。 | 平滑，无感知，极大提升了用户体验和系统抗压能力。 |
| **`expireAfterAccess`** | 优化缓存空间，移除不活跃的“冷”数据。     | 同步，长时间未访问则移除。                           | 对热点数据友好，但无法保证数据新鲜度。           |

**最佳实践建议：**

**总是将 `refreshAfterWrite` 与 `expireAfterWrite` 搭配使用**，让 `refresh` 负责日常的“平滑更新”，让 `expire` 负责最终的“强制清理与兜底”。这种组合能在保证数据相对新鲜的同时，提供极高的读取性能和系统稳定性。