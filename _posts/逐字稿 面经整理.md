# Java基础

## 1. ==和equals有何不同

==，对于基础类型，是比较两者的值是否相同，对于引用类型，是比较两者的地址是否相同。

equals，对于Object，底层用的==。对于引用类型，如果没有重写，底层用的==，是比较的两者地址；如果重写，是比较两者的值是否相同。比如Integer这一引用类型，equals方法就被重写为比较两者的inValue是否相同。String类型同样，equals方法就被重写为逐个比较两者的每个字符是否相同。

另外，如果两个引用的地址相同，那值肯定相等。

## 2. 什么是方法重载？返回值不同算重载吗？

重载是一个类中定义多个同名方法。返回值不同，不算重载（override叫重写方法），参数值不同才算重载（例如参数值个数不同，或类型不同）。

## 3. finally中的代码一定会执行吗

正常情况下是。但如果try中的代码还没执行完程序就中止、JVM崩溃或因故障挂机了，那么finally中的代码不会执行。

比如try中有System.exit()语句，程序中止；(System.exit(0)会关闭钩子方法)

比如try中遇到死循环;

比如try中遇到死锁。

## 4. 多态的实现原理

多态就是指一个父类可以有多个子类，或者一个接口可以有多个实现类的表现形态。

多态的好处：提高代码的通用性、可维护性，使代码低耦合。

多态的实现依赖于两点：动态绑定和虚拟方法调用。

动态绑定：编译时，绑定的对象类型是声明类型，将实现类型的绑定推迟到运行时来做。

虚拟方法调用：除了private、static和final方法，其他方法称为虚拟方法，和动态绑定对应，在运行时实际调用的是实现类或者是子类的实现方法，而不是声明类的方法。

## 5. ArrayList和LinkedList的区别

ArrayList和LinkedList的联系：

1. 都是Collection集合类下，List集合的子类。
1. 放入的位置是有序的，可以通过下标取出元素。

ArrayList和LinkedList的区别：

|                   | ArrayList                                                    | LinkedList                                                   |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img width=200/>  | <img width=200/>                                             | <img width=200 />                                            |
| 底层结构          | 底层是数组                                                   | 底层是双向链表，可以用作实现队列和栈。<br/>实现栈：list.push(x) ，list.pop(),  list.peek()<br />实现队列：list.offer(x)， list.poll(),  list.peek()<br />pop和poll是一样的，都是取队首; 区别在于，push是放队首，offer是放队尾。 |
| 取某一index的元素 | ArrayList快                                                  |                                                              |
| 查找某一元素      | ArrayList用for循环根据标逐个遍历，LinkedList用iterator逐个next遍历，两者差不多 |                                                              |
| 插入效率          | 如果插入位置靠头部，LinkedList快，ArrayList需要复制插入后的部分；<br />如果插入位置在中间，ArrayList快，因为LinkedList会从头或者尾往中间遍历找到目标位置；<br />如果插入位置靠尾部，ArrayList快，ArrayList不需要复制，LinkedList虽然也不需要遍历找位置，但需要新建结点并断链子接链子 |                                                              |
| 删除效率          | 同上                                                         |                                                              |

​			Collection

​				/		|

​			List		Queue

​		/				|

​	abstractList		Deque

​		|		\		|

​	ArrayList	LinkedList	



<img src="E:\工作相关文档\1111跳槽\面经\1714201063407.png" alt="1714201063407" style="zoom: 65%;" />

​	

<img src="E:\工作相关文档\1111跳槽\面经\LinkedList.png" alt="1714201166561" style="zoom:65%;" />

## 6. HashMap、LinkedHashMap、ConcurrentHashMap的区别



|          | HashMap                                                      | LinkedHashMap                                | ConcurrentHashMap                                            |
| -------- | ------------------------------------------------------------ | -------------------------------------------- | ------------------------------------------------------------ |
| <img zw> | <img width=200/>                                             | <img width=200/>                             | <img width=200/>                                             |
| 底层结构 | 底层由散列表（数组+链表/红黑树）构成                         | 底层由散列表（数组+双向链表）构成            | 底层由散列表（数组+链表/红黑树）构成                         |
|          | 初始容量是16，装载因子是0.75<br />当数组长度大于64且链表长度大于8，链表转为红黑树;当链表长度小于6，转回链表<br />哈希值的计算是key的hashcode的值取高16位再和hashcode值本身做异或。 | 遍历的是双向链表，所以初始容量不影响遍历速度 | 线程安全是由CAS和synchronized来实现的；<br />CAS的作用：<br />1. 每次在涉及到属性值或者是元素操作时，判断内存值和获取到的值是否相同，如果相同才能修改为目标值<br />2. put操作时如果结点为null，就用CAS+自旋的方式进行赋值<br />synchronized：<br />当某些操作需要加局部锁的时候，比如插入结点的时候。 |
| 查询过程 | 和ConcurrentHashMap相同，就是3步骤少了fwd的判断<br />3. 判断寻址位置是否是树结构，如果是，就按树的方式去查 |                                              | 1. 判断数组是否为null或者key的hash值落的对应位置是否为null，如果是，返回null结束<br />2. 如果不为null，判断寻址到的头结点的key是否就是要找的key，如果是，直接返回<br />3. 判断寻址位置是否eh<0, 表示是树结点或者fwd结点（表示正在扩容），如果是，则通过find方法去查。如果正在扩容，并且是fwd结点，会到新的数组nextTab上去查，否则，在旧数组上查<br />4. 否则就是普通链表，顺着头结点直接往后遍历查 |
| 插入过程 | 和ConcurrentHashMap相同，就是去掉了CAS和synchronized、并发扩容的过程<br />1. 首先计算key的hash值，即插入位置<br />2. 判断数组是否为null，如果是，初始化数组<br />3. 如果插入位置为null，直接插入<br />4. 如果插入位置不为null，判断头结点的key是否相等，如果相等，直接覆盖掉头结点的value，插入完成<br />5. 如果头结点key值不等，判断如果头结点是树结点的话，按树的方式插入<br />6. 否则按链表插入<br />7. 插入后判断是否需要扩容 |                                              | 1. 首先计算key的hash值，即插入位置<br />2. 判断数组是否为null，如果是，初始化数组<br />3. 如果插入位置为null，直接CAS插入<br />4. 如果插入位置不为null，判断是否为fwd结点，即正在进行扩容，如果是则加入扩容；如果不是，则synchronized锁住头结点进行插入操作<br />5. 如果fh>=0, 说明插入链表，否则插入树<br />6. 判断插入后是否需要链表转树<br />7. 执行addCount，判断是否开始扩容或加入扩容<br /> |
|          |                                                              |                                              |                                                              |
| 扩容过程 | 遍历旧数组进行扩容，如果只有一个头结点，直接放到新数组对应位置（hash&（2n-1）），否则分别按树和链表的方式进行拆分。如果是链表，旧数组的偶数位和奇数位会被分别放到新数组的低桶位（旧位置）和高桶位（旧位置+n） |                                              | 1. 判断是否是首次触发扩容的线程，如果是，初始化新数组nextTab<br />2. 从数组高位到低位进行遍历，如果是null，置为fwd结点；如果不是null，synchronized锁定头结点，进行迁移操作<br />3. 初始化高位和低位的头结点，计算待迁移的桶的每个结点的位置（其实和HashMap一样，也是奇数位和偶数位间隔着来），分别放到高位和低位上<br />4. 每个桶迁移完后，头结点置为fwd结点，标志可以继续向下一个桶进行扩容。 |

HashTable和Vector一样被淘汰了，通过在所有实现方法上加synchronized来实现的，低效。

![hash继承图](E:\工作相关文档\1111跳槽\面经\hash继承图.png)

## 7. 为什么JDK1.8 HashMap从头插变成尾插？

JDK1.7的时候采用头插法，扩容时会产生环形链表。

为什么JDK1.7的时候采用头插法，hashMap扩容时会产生环形链表？

答：在单线程环境下，无论是头插法还是尾插法，扩容过程都是安全的，不会产生环形链表。问题出在**多线程并发扩容**时，头插法会改变链表中元素的顺序，这个特性与并发操作结合，导致了循环引用。

## 7. 为什么JDK1.8 ConcurrentHashMap放弃分段锁？

1. 粒度和并发程度。分段锁锁的粒度太大，同一时间如果不同线程想修改同一个数据，会锁住整个分段，包括分段下的HashEntry，每个HashEntry内的所有数据。并发程度不够高。而JDK1.8的分离锁，锁的是桶，粒度更小，并发程度更高。
2. 扩容。分段锁在涉及扩容时会锁住整个map，重新分配段数据。对性能有很大影响。而JDK1.8扩容时锁的只是迁移的当前桶，性能更高。

## 8. 哈希冲突的解决方案有哪些？

1. 链地址法，HashMap用的就是这种
2. 再哈希法，二次计算个新的hash位置
3. 开放地址法，例如线性探测，还是找一个新的hash位置

## 9. CopyOnWriteArrayList，线程安全的List

CopyOnWriteArrayList是juc包下的类：import java.util.concurrent.CopyOnWriteArrayList;

实现方式：类中定义了一把锁，插入元素add和删除元素remove的时候，都是通过上锁和解锁保证线程安全。

Vector也线程安全，但已经被淘汰，它是通过在所有实现方法上加synchronized来实现的，低效。

<img src="C:\Users\zhumi\AppData\Roaming\Typora\typora-user-images\image-20240427194938372.png" alt="image-20240427194938372" style="zoom:67%;" />

<img src="C:\Users\zhumi\AppData\Roaming\Typora\typora-user-images\image-20240427195101537.png" alt="image-20240427195101537" style="zoom:80%;" />

<img src="C:\Users\zhumi\AppData\Roaming\Typora\typora-user-images\image-20240427195247849.png" alt="image-20240427195247849" style="zoom:80%;" />

<img src="C:\Users\zhumi\AppData\Roaming\Typora\typora-user-images\image-20240427160956367.png" alt="image-20240427160956367" style="zoom:65%;" />

## 10. 抽象类和接口有什么区别？

相同点：

1. 都不能直接实例化
2. 子类或者实现类都必须实现父类的所有抽象方法。

不同点：

​	抽象类：

		1. 由abstract class实现
		1. 抽象类中可以声明抽象方法或者实现普通方法
		1. 抽象方法不能被private修饰（因为它要被实现）
		1. 抽象类可以包含变量（比如普通变量和静态变量）和常量
		1. 一个类只能继承一个抽象类
		1. 可以有构造函数

​	接口：

	1. 由interface实现
	1. 接口中只能声明抽象方法
	1. 接口方法只能是public的
	1. 接口只能包含常量
	1. 一个类可以实现多个接口
	1. 没有构造函数

## 11. 什么是反射？反射的底层实现原理

**反射**：是能够在运行时获取类、类相关属性和方法的一种方式。

**反射的使用**：

​	Class clazz = Class.forName("User");

​	Method method = clazz.getDeclaredMethod("getUserName");

​	clazz.getDeclaredFields("");

​	clazz.getDeclaredConstuctor();

​	method.invoke(clazz.newInstance());	

**反射的使用场景**：

1. 运行时创建类，或使用类相关属性和方法
2. 动态代理底层依赖反射实现，用反射创建代理对象、调用方法等。比如实现AOP功能（日志记录，事务管理）
3. Spring框架的依赖注入是通过反射实现的（todo 后面Spring章节有）

**反射的优点**：

1. 灵活性
2. 可扩展性
3. 提高程序的可维护性和可测试性

**反射的缺点**：

1. 违反访问权限控制，破坏封装性：可以随时访问和修改类的字段和方法，会导致安全问题
2. 性能问题：运行时动态获取类信息，比编译时获取要更损耗性能。

**反射底层是如何实现的**：核心是invoke方法的实现。

1. 调用invoke时，JVM首先查找该方法是否存在
2. 然后进行安全检查，检查访问权限
3. 对方法参数进行转换和适配，包括类型检查和拆箱装箱操作
4. 实际方法调用，通过JNI（java本地接口）调用JVM本地方法
5. 异常处理，如果执行过程出现异常，JVM会捕获抛出InvocationTargetException
6. 返回结果

## 12.深克隆和浅克隆有什么区别

当被克隆对象包含引用属性（非基本类型属性）时，体现出来。

**浅克隆**：克隆后的对象的引用属性改变，被克隆对象对应的属性也会被改变

**深克隆**：克隆后的对象的引用属性改变，不影响被克隆对象

**浅克隆实现**：

任意对象implement clonable，重写clone方法，返回super.clone()克隆出的对象就是浅克隆的。

**深克隆实现**：

1. 在浅克隆的基础上，加一步，把所有引用属性也clone()一下并且set进去就可以了
2. 用FastJson工具序列化被克隆对象，再反序列化得到克隆对象，该对象就是深克隆的了。

**使用场景**：如果被克隆的对象只涉及一些基本数据类型或者String，根本不涉及引用类型的属性，简单使用浅克隆，简单效率高。反之，使用深克隆保证正确性，相应地，序列化和反序列化操作会损失一点性能。

## 13.如何使用链式调用(流式编程)？

优点：简洁可读

实现方式：

1. set方法，增加新的set方法，比如名叫name的方法，区别在于，在原有的set值基础上，加上返回对象本身就可以了。用的时候这么用：new Student().name(""); 说白了就是调用对象的方法而已。
2. lombok的@Builder注解。直接在要用的类上@Builder注解，就可以直接用了。用的时候，这么用：Student.builder().name("").build();



## 14. java内存模型（JMM）和内存结构

为什么要有java内存模型：为了屏蔽不同硬件和操作系统的底层内存细节，使得java在不同操作系统上对内存的操作都能有一致的数据表现。

## 15. java源码中的单例模式

‌**在Java中，许多类使用了单例模式来确保只有一个实例的存在。以下是一些常见的类及其使用单例模式的场景**‌：

1. ‌**[线程池](https://www.baidu.com/s?sa=re_dqa_generate&wd=线程池&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)（如[ExecutorService](https://www.baidu.com/s?sa=re_dqa_generate&wd=ExecutorService&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)）**‌：线程池在Java中用于管理一组工作线程，以减少在创建和销毁线程的开销。使用单例模式可以确保全局只有一个线程池实例，避免重复创建线程池导致的资源浪费‌1。
2. ‌**[缓存](https://www.baidu.com/s?sa=re_dqa_generate&wd=缓存&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)（如[Cache](https://www.baidu.com/s?sa=re_dqa_generate&wd=Cache&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)）**‌：缓存是用于存储和读取数据的一种机制，通常需要全局访问。使用单例模式可以确保缓存的唯一性，避免多个缓存实例之间的数据不一致问题‌1。
3. ‌**[日志记录器](https://www.baidu.com/s?sa=re_dqa_generate&wd=日志记录器&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)（如[Logger](https://www.baidu.com/s?sa=re_dqa_generate&wd=Logger&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)）**‌：日志记录器用于记录程序的运行状态和错误信息。使用单例模式可以确保全局只有一个日志记录器实例，方便统一配置和管理‌1。
4. ‌**[注册表](https://www.baidu.com/s?sa=re_dqa_generate&wd=注册表&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)（如[Registry](https://www.baidu.com/s?sa=re_dqa_generate&wd=Registry&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)）**‌：注册表用于存储和管理系统配置信息。使用单例模式可以确保全局只有一个注册表实例，避免配置信息的重复和冲突‌1。
5. ‌**[数据库连接池](https://www.baidu.com/s?sa=re_dqa_generate&wd=数据库连接池&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)**‌：数据库连接池用于管理数据库连接，确保数据库连接的高效使用。使用单例模式可以确保全局只有一个数据库连接池实例，减少连接创建和销毁的开销‌1。
6. ‌**[Spring框架中的Bean](https://www.baidu.com/s?sa=re_dqa_generate&wd=Spring框架中的Bean&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)**‌：在Spring框架中，许多Bean默认是单例的，这意味着在整个应用中只有一个实例。这通过Spring的依赖注入机制实现，确保了Bean的单例性‌2。
7. ‌**[MyBatis框架中的Mapper接口](https://www.baidu.com/s?sa=re_dqa_generate&wd=MyBatis框架中的Mapper接口&rsv_pq=fdae55cb01f88a86&oq=java源码哪些类使用了单例模式&rsv_t=d90cHgdo/gXIfDwTRuKYuzGFGhZvoFdxofmIS2r8xUsUcgVunh/Mdq3zTHUubgidEDBO&tn=baiduhome_pg&ie=utf-8)**‌：MyBatis通过代理模式为Mapper接口生成实现类，并将这些实现类加入到IOC容器中。虽然Mapper接口本身没有实现类，但通过代理模式实现了单例模式的效果‌2。

这些类通过单例模式的使用，确保了全局只有一个实例的存在，避免了资源浪费和冲突，提高了系统的稳定性和效率。

# JVM

## 1.如何进行JVM调优

先看调优原因，是有性能目标还是出现了生产问题。

1. 如果是希望获得更大的吞吐量可以使用Parallel Old和Parallel Scavenge垃圾回收器。如果想获得更短的停顿时间，可以使用G1垃圾回收器，并配置停顿时间。

2. 如果是请求压力过大，需要优化响应速率。一般是数据库先产生瓶颈，可以考虑引入高速缓存、进行读写分离或者分库分表。

3. 如果是生产出现了OOM。首先考虑是否需要扩容，观察运维平台的CPU占比和内存使用占比，适当调整核心数量和内存大小。

   如果调整后仍然OOM，可以使用top、jps、jstack、jmap等指令进行排查。top可以看到cpu或者内存占用高的进程，jstack可以排查死循环和死锁，jmap -heap 进程id，可以排查堆的使用情况，jmap -histo可以看到大对象类。jmap -dump可以导出文件，到 J VisualVM中去分析。

## 2. 什么是类加载器

是JVM的重要组成部分，负责将字节码文件加载到内存中，并转换为可执行的类。

**启动类加载器**：加载启动类、本地方法类

**扩展类加载器**：加载扩展类

**应用类加载器**：也叫系统类加载器，加载程序的类文件。

**自定义类加载器**：自定义MyClassLoader，extends ClassLoader，并且重写loadClass方法

Tomcat会给每个Web应用一个独立的WebAppClassLoader类加载器。往上，不同Web应用之间共享的类用SharedClassLoader加载，另外，还有类加载器CatalinaClassLoader，加载Tomcat自身要用的类。再往上，CommonClassLoader用来加载Tomcat和Web应用共享的类。

**双亲委派机制**：先委托给父类，直到找到最上层的父类加载器，如果找不到，子类加载器才去加载。

重写了loadClass方法，不再按应用—>扩展—>启动这样的顺序逐级向上找就是打破双亲委派机制。如上，Tomcat也打破了。

## 3. 类从编译到执行的过程

编译—>加载—>解释—>执行。

编译：生成字节码文件。

加载：第二步的加载就是下面的类加载4。

解释：把字节码转换为操作系统可以识别的指令

执行：执行硬件指令。

## 4. 类是如何被加载的

装载、连接、初始化。

装载：通过类加载器，查找并装载类的二进制文件

连接：验证、准备、解析。

1. 验证：验证装载的类是否符合java虚拟机规范
2. 准备：为类的静态变量分配内存，设置默认初始值
3. 解析：将符号引用转为直接引用。

初始化：执行类的初始化代码，进行静态变量的赋值和静态代码块的运行。

## 5.java内存结构

1. 程序计数器。如果执行的是java方法，保存的是程序当前执行的指令的地址，如果执行的是native本地方法，是空。
2. 本地方法栈。调用native方法时会使用的栈。
3. 虚拟机栈（java方法栈）。调用java方法时会使用的栈，调用每个方法会生成一个栈帧。
4. 方法区：放类的基本信息。新版本的常量池已经放到堆中。常量池包含静态常量池（包含字符串常量池）和运行时常量池。
5. 堆：存放对象和数组。
   1. 堆分为年轻代和老年代，1:2。年轻代分为eden、from survivor、to survivor，8:1:1。对象大部分放在eden区和from survivor区，每次minor jc，这两个区的存活对象会被复制放到to survivor区，这两个区会被清空，存活对象岁数＋1。
   2. 年轻代eden区满会进行minor gc。老年代满了会进行major gc或者full gc。full gc会对年轻代和老年代全部回收
   3. 年轻代15次minor gc仍然存活的对象，放入老年代。太大年轻代放不下的对象，放入老年代。

## 6. 如何判断对象是否存活

可达性分析算法。

## 7. 什么对象可以作为GC Roots

栈帧的栈顶对象、本地方法栈中的对象、静态变量、常量

## 8.常见的垃圾回收算法

1. 标记清除：效率高，有内存碎片
2. 复制：不存在内存碎片，需要预留额外的内存，内存利用率不高
3. 标记整理：效率低，不存在内存碎片
4. 分代算法：新生代采用复制算法，老年代采用标记清除或标记整理。

## 9. 常见的垃圾回收器

serial /Serial Old

Parallel scavenge/Parallel Old：java8默认。

CMS

G1：java9默认。

ZGC

## 10. 说说ZGC

1. 并发回收
2. 超短停顿时间：10ms，采用微任务。
3. 压缩空间：防止内存碎片
4. 大内存支持：最大10到100GB

## 11. 什么是即时编译器

在程序运行时，将热点代码直接编译成机器代码，提高程序执行性能。

## 12.内存泄漏和内存溢出的不同

内存泄漏：对象使用后没有正常回收，导致内存被浪费，虽然累积，可能会导致内存溢出。

内存溢出：内存被占满，导致方法区溢出、栈溢出、堆溢出。方法区溢出可能是动态规划的不当实用，生成了大量代理类。栈溢出可能是不当的无限递归调用。堆溢出的原因有很多，比如创建了过多的大对象，数组对象，或者内存分配不足。

# Spring全家桶

## 1. 什么是spring框架？有哪些特性/优点？

Spring框架是一个企业级的java应用程序开源框架，能够开发灵活、可扩展、解耦的应用程序，并且能够快速构建企业级应用程序。

Spring框架的几个特性：

1. 轻量级和框架整合：依赖少量的第三方库，很方便的进行依赖框架的管理，并且有选择地引入，无需引入整个框架。也很方便地引入其他技术框架，帮助构建全面的应用程序。
2. 控制反转：通过IOC容器管理对象和对象间的依赖关系，将Java Bean的创建、组装和生命周期的管理交给Spring框架，实现了松耦合。
3. 面向切面编程：帮助模块化切面关注点的相关逻辑，集中处理，减少对业务逻辑代码的侵入，实现比如日志记录、事务管理等。
4. 声明式事务：通过注解或者XML的方式，在方法或类上实现事务管理，事务相关逻辑不会再侵入业务逻辑。
5. 可测试性：很好地支持单元测试和集成测试，帮助验证应用程序。

## 2. 什么是IOC？IOC的实现原理

IOC控制反转是Spring框架的核心特性之一，意味着将java对象以及对象之间的依赖交给容器来管理。

**优点**：能够使程序松耦合、可维护、可扩展。

**实现方式**：DI依赖注入或依赖查找。

依赖注入：由容器查找对象所依赖的对象，并且将依赖关系注入对象中，实现对象之间的解耦。依赖注入可以由构造函数注入、setter注入或者接口注入来实现。

依赖查找：开发人员通过调用容器提供的API手动查找并获取需要的对象实例，从而实现对象之间的解耦。API是ApplicationContext接口的getBean方法。

两者的区别是：依赖注入中容器既负责对象的管理，又负责依赖对象的查找。而依赖查找中容器只负责对象的管理，由对象本身负责查找自身所依赖的对象。

**实现原理**：下面说到DI的实现原理是反射，而DI又是IOC的实现方式，那么自然反射也可以说是IOC的实现原理。IOC的实现原理是工厂模式+反射。实现流程如下：

1. 首先通过ApplicationContext创建一个容器
2. 创建一个工厂类，通过工厂类的createBean方法，以反射的方式创建配置文件中类名对应的类实例，放入到Spring容器中
3. 在使用DI时，就从Spring容器中找到类名对应的类实例。

## 3. DI的实现原理

依赖注入作为IOC的实现方式，它自身的实现原理是反射机制。

前面提到过，依赖注入是由容器去查找对象的依赖对象，那么这个查找就是通过反射实现的。属于运行时获取对象的范畴。

比如使用@Autowired进行注入的时候，就是Spring容器去查找与该类型匹配的Bean，并注入到该属性中。

## 4. 什么是AOP？AOP的实现原理

AOP是面向切面编程，指编写切面逻辑，并指定插入切面的切点，进而实现对切入点的方法的代码增强或者减弱。

Advice通知：这个概念就说白了就是切面里具体的实现代码，比如@Around、@Before、@After注解下的代码。

**优点**：显然，把切面逻辑从业务逻辑中分离出来，以及，提高代码的灵活性、可重用性、可扩展性、可维护性。

**实现原理**：JDK动态代理和cglib动态代理。并且Spring通过代理工厂ProxyFactory实现代理类创建和管理。当调用被代理类的方法时，代理类会根据切入点拦截相应请求，交由代理类，根据切面的通知类型，执行不同类型的通知逻辑。

如果被增强的类有实现接口，那么底层用JDK动态代理实现。如果没有实现接口，那么底层用cglib动态代理实现。

JDK动态代理：通过InvocationHandler接口和Proxy类实现代理。return Proxy.newProxyInstance(classLoader, interfaces, invocationHandler); 会在运行时实现代理接口，并实现其中的方法，在方法前后调用切面逻辑。

cglib动态代理：通过MethodInterceptor接口和Enhancer类实现代理。return Enhancer.create(class, methodInterceptor); cglib通过字节码技术生成被代理类的子类，在子类中重写目标方法并在方法前后调用切面逻辑。

## 5. 静态代理和动态代理的对比

**静态代理**：编译时就已经确定代理关系的代理方式。被代理类和代理类实现同一个接口或者父类，代理类拥有被代理类的实例，并在被代理类的实现方法前后执行额外的操作。

**优点**：实现简单。

**缺点**：每一个被代理类都需要一个自己的代理类，可能需要创建很多代理类。

**动态代理**：在运行时生成代理类的代理方式。可以多个被代理类生成同一个代理类（其实一个代理类可以被多个被代理类使用，比如在切面的pointCut注解里指定了多个会被拦截的类）。

优点和缺点就是静态代理的反面。

## 6. Bean的生命周期

1. Bean实例化：就是调用构造函数。为对象分配内存空间。单例模式的实例在容器启动时就被实例化，多例模式的Bean在请求时才被实例化
2. Bean属性赋值：通过xml中的property属性或者注解中指定值实现，对实例属性赋值
3. 初始化：可以通过实现InitializingBean接口或者@PostConstruct来实现
4. 执行：建好的Bean可以操作了
5. 销毁：可以通过DisposalBean接口或@PreDestroy实现。Spring容器关闭时，会自动销毁所有Bean

## 7. Spring中Bean有几种作用域

singleton、prototype、request、session、application（在ApplicationContext上下文中有效）

## 8. 单例Bean是否安全？

分情况，如果是无状态的Bean（即无属性的Bean），那么单例安全。如果是有状态的Bean（即有属性的Bean，意味着有共享变量），那么单例在多线程时不安全。

怎么解决单例多线程时不安全：

1. 定义ThreadLocal类型的属性，ThreadLocal变量是线程独立的
2. 使用线程安全的类，比如ConcurrentHashMap、CopyOnWriteArrayList、Automic包下的类
3. 使用synchronized或者ReentrantLock加锁
4. 使用@Scope("protoType")，不再使用单例模式，变成多例，每次注入会返回一个新的实例。

## 9. FactoryBean和BeanFactory的区别

两者都是接口。

FactoryBean有几个接口方法，getObject、getObjectType和isSingleton。可以通过实现该接口自定义一些初始化操作并返回实例对象。

BeanFactory是Spring框架的一个基础容器，FactoryBean也是由BeanFactory来管理的。BeanFactory负责对象的创建、生命周期管理以及依赖管理，可以使用getBean()方法来获取对象实例。

## 10. @Autowired底层是如何实现的

@Autowired做的是通过属性注入的方式进行依赖注入，那么依赖注入的底层实现方式是工厂模式+反射。

Spring启动的时候，IOC容器会扫描应用程序所有Bean并将Bean实例放在一个BeanFactory中，后续注入的时候会从中查找取出，查找使用的就是反射机制。

## 11. @Autowired和@Resource的区别

1. @Autowired是通过类型查找类，如果存在多个类型相同的类，再通过类名查找，@Resource是反过来的，先类名再类型。

2. @Autowired支持3种注入：属性注入、setter注入和构造方法注入，而@Resource不支持构造方法注入

## 12. Spring中使用了哪些设计模式

1. 工厂模式：BeanFactory作为Spring的一个基础容器类，使用了工厂模式,通过getBean()来获取对象实例。ProxyFactory作为代理工厂，通过getProxy方法返回生成的代理对象。
2. 代理模式：AOP使用到了动态代理模式，包括JDK动态代理和cglib动态代理。
3. 模版方法模式：比如没有具体实现逻辑的父类方法AbstractBeanFactory的createBean，它是交由子类来延迟实现的。



## 13. 你在工作中使用了哪些设计模式

1. 代理模式：日志收集、事务管理都涉及到使用AOP，依赖的就是动态代理
2. 模版方法模式：审批流程相关业务，会先定义一个流程框架，放置一些固有的执行步骤，这些步骤可以在具体流程，比如工单申请流程，数据库申请流程等不同流程的子类中有选择的具体实现。
3. 工厂模式：把创建对象的工作交给工厂，不再通过new这种耦合性强的方式创建，而是通过xxxFactory.getObject()或者xxxFactory.createObject()，这种方式来屏蔽创建对象的细节，方法名是什么不重要。利于代码的可扩展性。
4. 单例模式：如下

## 13. 在工作的什么场景用到了单例模式

1. 配置信息管理器（Configuration Manager）

   在启动时需要加载系统参数等配置信息。如`appsettings.json`, `application.yml`）或环境变量

   

       public class ConfigManager {
           private static ConfigManager instance;
           private Properties properties;
       
       private ConfigManager() {
           // 私有构造方法，防止外部new
           loadConfigs(); // 在构造方法中加载配置
       }
       
       public static ConfigManager getInstance() {
           if (instance == null) {
               synchronized (ConfigManager.class) {
                   if (instance == null) {
                       instance = new ConfigManager();
                   }
               }
           }
           return instance;
       }
       
       private void loadConfigs() {
           properties = new Properties();
           // 从文件或环境变量加载配置...
       }
       
       public String getProperty(String key) {
           return properties.getProperty(key);
       }
       
       }
       
       // 使用方式：在任何需要的地方，通过单例获取配置
       String dbUrl = ConfigManager.getInstance().getProperty("database.url");
   
   

   

## 14. Spring和SpringBoot有什么区别？

从SpringBoot的优点上来说。SpringBoot的优点属于它有而Spring Framework没有的。

1. 简化配置、自动装配和起步依赖。Spring需要引入多个依赖，并且配置spring.xml文件，手动配置一些细节才能启动一个应用。而Spring Boot只需要引入很少的依赖，配置简单的application.yml或application.properties就可以启动一个应用。因为SpringBoot可以根据spring.factories文件自动获取相关的配置类信息，自动配置相关的组件。起步依赖可以帮助快速集成需要的相关依赖，并解决依赖冲突和版本问题。
2. 嵌入式服务器。Spring需要依赖外部的服务器才能部署应用。而SpringBoot自带嵌入式的服务器，比如Tomcat或Jetty，可以一键启动应用程序，简化了部署流程。
3. 自动化监控。SpringBoot集成了Actuator模块，可以实现对应用程序的自动化监控、管理和运维支持。方便故障排查和性能优化。

## 15. 什么是SpringBoot自动装配

自动装配指的是不需要手动在xml文件中进行大量组件的相关配置，由SpringBoot根据配置文件自动装配需要的组件。

自动装配的实现原理：

1. 应用启动时会创建一个SpringApplication实例，并自动装载spring.factories文件中配置的自动装配类
2. 调用SpringApplication的run方法，创建Environment实例和ApplicationContext实例
3. ListenableBeanFactory加载ApplicationContext中的所有BeanDefinition，并根据@Conditional注解装配自动装配类
4. 扫描@EnableAutoConfiguration和@Configuration注解，装配Bean
5. 装配完成后，Spring boot启动内嵌的Web服务器，完成启动。

## 16. 如何实现缓存预热/应用启动初始化？

1. 实现InitializingBean接口，重写afterPropertiesSet方法。
2. 使用@PostConstruct注解
3. 实现ApplicationListener接口，重写onApplicationEvent方法进行启动监听。

## 17. 获得request对象的几种方法

1. 请求参数中通过HttpServletRequest获取
2. RequestContextHolder.getRequestAttributes().getRequest()获取
3. @Autowired自动注入HttpServletRequest获取

## 18. 如何实现拦截器和过滤器

**实现拦截器**：

1. 自定义拦截器类，注解@Component
2. 实现HandlerInterceptor接口，implement HandlerInterceptor
3. 重写preHandler（请求的方法执行之前执行）、postHandler、afterCompletion方法
4. 指定要拦截哪些请求地址。自定义一个配置类，注解@Configuration，实现WebMvcConfigurer接口，重写addInterceptors方法。

**实现过滤器**：

1. 自定义过滤器，注解@Component，指定拦截地址@WebFilter(urlPatterns="/*")，实现Filter接口，implement Filter。
2. 重写init(Filter对象的初始化)、doFilter、destroy方法。其中doFilter方法写拦截前要做的逻辑，加filterChain.doFilter(request,response)放行逻辑。

## 19. 拦截器和过滤器的区别

1. 拦截器Interceptor是Spring框架的，过滤器是Java自带的
2. 执行的时机不同。请求会先到过滤器，再到拦截器，再到控制器。
3. 功能不同。过滤器只能做前置处理，而拦截器可以做请求的前置和后置处理。也就决定了各自的应用场景不同，比如过滤器可以做敏感词过滤，字符集编码设置，而拦截器除了这些还可以做请求响应时间等日志收集。

## 20. 工作中使用过什么自定义注解

**场景**：使用自定义注解进行日志记录或权限验证。

**自定义注解实现方式**：AOP或拦截器

AOP实现步骤：

1. 自定义注解，@interface关键字，使用注解@Target指定作用的是Method，使用注解@Retention指定是运行时。定义注解的属性。
2. 编写AOP的切面类，使用注解@Component、@Aspect在类上，使用@Around("@annotation(自定义注解参数变量)")自定义一个方法，由方法前执行的逻辑+jointPoint.proceed()+方法后执行的逻辑组成。比如可以记录方法执行前后的时间。
3. 使用自定义注解，直接在要加切面的方法上@自定义注解，就可以了。

拦截器实现步骤：略。

## 21. 声明式事务生效条件

Spring中@Transactional声明式事务生效需要：

1. 修饰的是public方法

2. 没有注解在同类子方法上（因为事务注解默认是只有外部去调用方法AOP才会去拦截，同一个类中调用子方法时不会触发拦截的）。

   规范的使用方法：

   1. 被调用的方法写在controller层，需要独立注解的方法写在Service层。（参考https://blog.csdn.net/wang_lianjie/article/details/103574836）
   2. 被调用的多个方法都写在Service层，需要独立注解的方法分成不同的Service。（参考https://blog.csdn.net/yuxiangdeming/article/details/125243814）

3. 异常没有被捕获，try catch住了注解不能识别到异常了
4. 数据库至少要支持事务

## 22. 如何解决跨域

**跨域是什么**：请求协议不同，或域名不同，或端口不同

**如何解决**：

1. 使用@CrossOrigin，可以实现类上或者方法上的跨域。但只能每个类注释一遍，没法实现全局跨域。
2. 自定义配置类实现跨域。注解@Configuration，实现WebMvcConfigurer接口，重写addCorMappings方法，方法里添加支持的指定域就可以了，比如allowedOriginPatterns(*)。
3. 实现ResponseBodyAdvice接口实现跨域。这个方法很重要，就是跨域的本质。注解@ControllerAdvice（拦截所有请求），重写beforeBodyWrite方法，设置响应头response.getHeaders().set("Access-Control-Allow-origin",true)

## 23. 说一说你读过的源码

synchronized的底层C++，ObjectMonitor管程或者叫监视器锁的源码。（描述一遍）

1. 几个核心变量。owner，
2. 修饰方法时和修饰代码块时涉及的指令。
3. 锁升级的过程。无锁状态——>偏向锁——轻量级锁——>锁自旋——>重量级锁（涉及用户态和核心态的切换，因为有一些指令的操作）。

Lock的底层实现。待看



**Spring Boot收到请求后的执行过程源码**：

1. 执行前端控制器DispatchServlet，调用父类FrameworkServlet的service方法，最终会调用DispatchServlet中的doService方法，再到doDispatch方法。
2. doDispatch方法中，首先会获取原生的request对象，然后通过HandlerMapping(处理器映射器)的getHandler方法获取HandlerExecutinoChain处理器执行链，执行链中包含处理器方法和拦截器列表
3. 通过HandlerExecutinoChain执行链获取HandlerAdapter处理器适配器（常用的有HttpRequest适配器和RequestMapping适配器），接着处理器适配器会调用handle方法具体执行处理器方法
4. 在handle方法的前后会执行拦截器的前置和后置处理方法
5. 处理器方法执行完逻辑后，可以将数据对象序列化后（JSON格式）返回给前端处理。或者使用ViewResolver视图解析器解析返回的模型数据，找到相应的View视图去渲染Html页面。

**Spring Cloud中的负载均衡组件源码**：

Spring Cloud LoadBalancer中的两个负载均衡算法分别是RoundRobinLoadBalancer和RandomLoadBalancer。

1. 轮询负载均衡的实现：调用原子类AtomicInteger类的incrementAndGet方法对当前位置加1，取绝对值，并对服务列表的个数取模，然后获取服务列表对应位置的服务实例。
2. 随机负载均衡的实现：通过ThreadLocalRandom的nextInt方法获取一个不超过服务列表大小的随机数，然后获取对应位置的服务。

# 微服务

微服务的特点：
单一职责：微服务中每一个服务都对应唯一的业务能力，做到单一职责
微：微服务的服务拆分粒度很小，例如一个用户管理就可以作为一个服务。每个服务虽小，但“五脏俱全”。
面向服务：面向服务是说每个服务都要对外暴露Rest风格服务接口API。并不关心服务的技术实现，做到与平台
                        和语言无关，也不限定用什么技术实现，只要提供Rest的接口即可。

自治：自治是说服务间互相独立，互不干扰
	团队独立：每个服务都是一个独立的开发团队，人数不能过多。
	技术独立：因为是面向服务，提供Rest接口，使用什么技术没有别人干涉
	前后端分离：采用前后端分离开发，提供统一Rest接口，后端不用再为PC、移动端开发不同接口
	数据库分离：每个服务都使用自己的数据源
	部署独立，服务间虽然有调用，但要做到服务重启不影响其它服务。有利于持续集成和持续交付。每个服
						务都是独立的组件，可复用，可替换，降低耦合，易维护

RPC：Remote Produce Call远程过程调用，RPC基于Socket，工作在会话层。自定义数据格式，速度快，效
率高。早期的webservice，现在热门的dubbo，都是RPC的典型代表。

Http：http其实是一种网络传输协议，基于TCP，工作在应用层，规定了数据传输的格式。现在客户端浏览器
与服务端通信基本都是采用Http协议，也可以用来进行远程服务调用。缺点是消息封装臃肿，优势是对服务的
提供和调用方没有任何技术限定，自由灵活，更符合微服务理念。
现在热门的Rest风格，就可以通过http协议来实现。

# 并发

## 1. 进程和线程有什么区别

1. 进程是系统资源分配的单位，线程是资源调度的单位。
2. 进程的上下文切换开销更大
3. 进程之间的通信相对较复杂，线程可以直接共享数据。进程拥有程序计数器，栈，方法区，堆，线程共享方法区和堆，私有程序计数器和栈（虚拟机栈和本地方法native栈）。

## 2. 线程等待和唤醒有几种实现

1. Object的wait()、notify()、notifyAll()。必须结合synchronized用，synchronized锁住某个对象Object。

2. Condition的await()、signal()、signalAll()。一把Lock可以new多个Condition。

   ```java
   Lock lock = new ReentrantLock();
   Condition condition = lock.newCondition();
   condition.await();
   condition.signal();
   ```



3. LockSupport的park()、unpark(Thread thread)。unPark可以唤醒指定线程。

   ```java
   LockSupport.park();
   LockSupport.unpark(thread1);
   ```

## 3. 线程通讯的几种方式

1. 等待唤醒机制。synchronized配合Object类的wait()、notify()、notifyAll()。
2. 锁机制。ReentrantLock配合Condition类的await()、signal()、signalAll()。
3. 栅栏机制。CyclicBarrier或CountDownLatch。CyclicBarrier类，每个线程执行完自己的业务后await()阻塞，等待所有线程都到达之后再一起向下一阶段执行。CountDownLatch类，每个线程执行完自己的业务后countDown减一，主线程await阻塞等待计数器为0后，继续向下执行。
4. 信号量机制。Semaphore类，acquire获取许可证，release释放许可证，许可证可以有多个。可以等价为多把锁。

注意：wait&notify和lock&unlock没有等价关系，两者是在有些时候互相配合使用，比如实现生产者/消费者机制。

## 3. 进程通讯的几种方式

1. 消息队列通信： 消息队列是操作系统内核提供的一个**消息链表**，用于在不同的进程之间传递数据块。（消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。）

2. 信号量（semophore）通信：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。

3. 共享内存( shared memory ) 通信：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。

4. 套接字( socket ) 通信：它可用于不同机器间的进程通信。命名socket，绑定，监听，连接服务器，相互发送接收数据，断开连接

## 4. java中的锁机制

1. synchronized关键字
2. Lock接口，ReentrantLock是一个实现类
3. ReadWriteLock接口，ReentrantReadWriteLock是其中一个实现类
4. StampedLock，java8引入，除了读锁readLock()，写锁writeLock()，增加了乐观读锁tryOptimisticRead()，提高并发性能。

**锁的种类**：

1. 乐观锁和悲观锁：synchronized和ReentrantLock都是悲观锁，操作数据前都会上锁；CAS是一种乐观锁，atomic包下的原子类是用CAS实现的。
2. 可重入锁：synchronized和ReentrantLock都是可重入的。StampedLock不可重入，所以在使用的时候要注意不要重复地尝试获取同一把锁来加锁，只获取一次。
3. 公平锁和非公平锁：synchronized是非公平锁，ReentrantLock默认也是非公平，可设置为公平
4. 独占锁和共享锁：synchronized和ReentrantLock都是独占锁；ReentrantReadWriteLock是共享锁。

**synchronized和ReentrantLock的区别**：

1. synchronized是java内置关键字，ReentrantLock是接口Lock的实现类
2. synchronized是不可中断的，需要一直等待其他锁释放。ReentrantLock是可中断的，比如可中断地获取锁lockInterruptibly()，如果获取锁的时候获取不到（其他线程已经占有锁），那么就会抛出中断异常，不会一直等待下去。
3. synchronized如果异常可以自动释放锁，ReentrantLock异常时不会自动释放锁，需要在finally中手动释放，否则会发生死锁。
4. synchronized获取锁失败不会重试，ReentrantLock使用tryLock(3, TimeUnit.Second)，可以在等待时间内重试获取锁
5. synchronized是非公平的，ReentrantLock可以设置为公平锁。
6. Lock的ReentrantReadWriteLock可以提高多个线程竞争读写时候的效率。读读不互斥，写与其他读写都互斥。而synchronized明显读读也是互斥的。

## 5. 什么是AQS，底层是如何实现的。

抽象队列同步器，一个抽象类，synchronized、ReentrantLock、Semaphore等锁相关类都是基于它实现的。包含acquire()、release()、tryAcquire()、tryRelease()方法。

**底层实现**：

通过state和双向队列实现的。如果线程获取锁成功，state加一，如果获取锁失败则入等待队列。

synchronized是基于AQS实现的。_owner表示占有锁的线程id，entryList和cxq队列是阻塞队列，waitSet是等待队列，count表示获取锁的次数。

## 6. synchronized底层是如何实现的

修饰方法时是通过accSynchronized指令实现的，修饰代码块时是通过moniterEnter和monitorExit指令实现的。

通过对象头中的Mark Word，轻量级锁时Mark Word的30位存指向栈帧中Lock Record的指针，重量级锁时Mark Record的30位存指向堆中Monitor的指针。

**无锁状态、偏向锁、轻量级锁、重量级锁**：

如果无线程占用锁，就是无锁状态。

如果只有一个线程，不存在竞争，线程到来获取锁，此时是偏向锁。

如果有多个线程竞争，锁已被占用，其他线程到来通过CAS竞争锁失败，会升级为轻量级锁。

如果轻量级锁时，CAS修改Lock Record指针失败，即仍然抢锁失败，并继续多次自旋抢锁失败，升级为重量级锁。

## 7. 什么是死锁，如何避免死锁

死锁就是多个线程相互持有资源，都不释放，并且循环等待。

**如何避免**：

1. Lock加锁使用完记得释放锁，分布式锁使用时，原生锁设置锁过期时间，Redission锁记得unlock释放锁。
2. 按顺序加锁
2. 避免分布式死锁，原生锁的优化。

**如何排查死锁**：使用jstack指令，查看进程状态和调用堆栈。-l，lock的意思，会打印出锁的信息deadLock。

```java
jstack -l pid号
```

## 8. 什么是CAS，如何解决CAS的ABA问题

比较并交换，一种乐观锁（无锁）。查询内存值并与获取到的当前值比较，如果相等才修改为目标值。

加上版本号可以解决ABA，即把A带上版本号，标志有没有变化，实现类是AtomicStampedReference。

## 9. 线程池有什么优点 

线程复用并且避免线程频繁创建和销毁带来的开销。

**线程池的几个参数**：

1. 核心线程数
2. 最大线程数
3. 空闲回收时间
4. 等待队列
5. 拒绝策略
   1. 抛出异常
   2. 以当前线程运行
   3. 丢弃最老线程
   4. 直接丢弃

## 10. 什么是volatile，底层是如何实现的

volatile修饰的变量代表修改对所有线程可见。

**底层实现**：

1. 通过MESI缓存一致性协议实现可见性。当volatile变量被修改，它会锁定当前缓存区域的缓存行，并快速写入主存，使其他缓存了该主存的缓存地址失效，它们会重新到主存中拉取数据。

2. 通过内存屏障来实现有序性。在内存屏障前后禁止指令重排序优化，在写之前插入StoreStore指令，写之后插入StoreLoad指令。读之前插入LoadLoad指令，读之后插入LoadStore指令。

## 11. 保证线程安全的手段有哪些

1. 锁机制
2. volatile，多线程下共享变量修改可见。
3. ThreadLocal，多线程下共享变量修改隔离。
4. 线程安全集合类，ConcurrentHashMap或CopyOnWriteAyyarList或Atomic包下的类

## 12. 举个例子你用过的ThreadLocal

场景一：拦截器里面要记录请求响应时间，使用ThreadLocal定义一个时间变量，preHandler和postHandler里面都可以操作，并且保证多线程下正确

场景二：RequestContextHolder在Service层获取request，依赖ThreadLocal实现的。两个ThreadLocal<RequestAttributes>变量。

（场景三：数据库连接池。因为可能不同线程从线程池拿到的是同一个连接，为了防止出现事务安全问题，ThreadLocal使得就算是同一个连接操作的也是自己独立的连接副本。）

# MYSQL 

## 0. mysql如何优化

1. 最大化利用索引优化查询：在频繁查询的字段上建立索引。

2. 规范使用索引查询，使索引命中。如最左匹配原则，覆盖索引（E:\工作相关文档\1111跳槽\222跳槽），以及避免使用表达式和函数计算

3. 分页查询时如果数据量大，可以利用子查询优化，先查询出id，再查询出对应记录

4. 如果需要优化查询效率，可以采用读写分离，主库写，多个从库分担读的压力。或者引入redis、es（优化字符串类的查询效率）。

5. 如果数据量不断增大，可以考虑进行分库分表。

   分表可以根据业务情况进行水平拆分或者垂直拆分。（**单表数据量最好控制在千万级别以内**）

   1. 垂直拆分：一般会把不常用的字段分离出去。

   2. 水平拆分：需要指定路由行到拆分后的表的方法，可以用取模法、hash法等。水平拆分后会带来一定的查询操作难度，例如join、count、order by等操作需要合并多次查询的结果。

   单台数据库一般可以支撑10万用户量级的业务，一般会根据业务的发展情况，不建议一上来就进行分库。分库后表之间的join、数据库事务等实现都会变得很复杂。

## 1. 关系型和非关系型数据库的区别

1. 关系型数据库比如mysql、Oracle，存储的数据是表的结构，列代表属性，行代表记录；非关系型比如redis，es存储的一般是<key, value>、文档或者图片的结构。
2. 关系型使用sql语言进行增删查改，非关系型一般有自己的语言，比如es的DSL语句
3. 关系型数据库可以支持事务，非关系型一般不支持事务

## 2. mysql的InnoDB和MyISAM引擎有什么区别

1. InnoDB支持事务，MyISAM不支持
2. InnoDB数据占用空间大，MyISAM相对小
3. InnoDB支持行锁，MyISAM只支持表锁
4. InnoDB适合多写的业务，MyISAM适合多查少写的业务
5. InnoDB支持外键、主键自增

**MyISAM已过时，不推荐用于生产**（E:\工作相关文档\1111跳槽\222跳槽）

## 3. 索引的分类有哪些

1. 普通索引
2. 唯一索引
3. 主键索引
4. 联合索引
5. 全文索引

## 4. 索引底层是如何实现的

**B+树**：

B+树是多路平衡搜索树，在聚集索引树上，它的非叶子结点不存储行记录，只存储主键，这样在最少的深度下存储更多的数据。叶子结点存储行记录。

**优点**

1. 存储更多的数据
2. 插入和删除的效率更高，有冗余结点，不需要进行树的调整。

3. 查找数据，遍历深度更小，进行磁盘IO的次数更少（页加载到内存）；并且取记录不需要在不同层之间跳转，查询速度更快。便于范围查询。

## 5. 聚集索引和非聚集索引的区别

聚集索引叶子结点放的是主键和行记录

非聚集索引叶子结点放的是索引列值和主键值，主键值用于回表到聚集索引上找对应的行记录。

## 6. 什么情况下会索引失效

1. 使用联合索引查询时，没有符合最左匹配原则
2. 对索引列使用了表达式或者函数计算
3. 使用is not null

| 导致失效的场景        | 示例                         | 优化思路                      |
| :-------------------- | :--------------------------- | :---------------------------- |
| **索引列上计算/函数** | `YEAR(date_column) = 2024`   | 将计算移至等号右侧            |
| **`NOT` 条件**        | `status IS NOT NULL`         | 难以优化，尽量避免            |
| **不慎用的 `OR`**     | `c1 = 'a' OR c2 = 'b'`       | 改用 `UNION` 或为所有列建索引 |
| **隐式类型转换**      | `varchar_column = 123`       | 确保类型一致                  |
| **`LIKE` 前导 `%`**   | `name LIKE '%abc'`           | 避免前导%，使用全文索引       |
| **违反最左前缀**      | 索引是 `(a,b)`，查询只用 `b` | 查询条件必须包含最左列        |

要最终确认 MySQL 是否使用了索引，最有效的方法是使用 **`EXPLAIN`** 命令来分析你的查询。

## 7. 最左匹配原则

当表有联合索引，查询条件最好从左到右匹配。不能去掉前面的，中间也不能中断。

比如一个联合索引（年龄，姓名，地址）

索引树的结点按年龄是有序的，姓名和地址是无序的。当年龄相同，姓名是有序的，地址是无序的。当姓名相同，地址才有序。

## 8. 事务的四大特性

**ACID**

原子性：要么一起成功，要么一起失败。通过undo log实现。

一致性

隔离性：事务之间的操作相互不影响。通过表锁行锁和MVCC实现。

持久性：修改持久到磁盘中，不丢失。通过redo log实现。

其他三个特性是为了一致性。

**4大隔离级别**：

读未提交：出现脏读。提升到读已提交解决。

读已提交：出现不可重复读。即两次读之间发生了修改操作。通过MVCC解决。

可重复读：出现幻读。即两次读之间发生了插入或者删除操作。通过MVCC+间隙锁解决。间隙锁就是select...for update。

串行化：没任何问题。效率低

**MVCC机制**：

每条记录携带两个隐藏字段，记录创建时的事务id和删除的事务id。

当读取时，只读取创建事务id小于或等于当前事务id，删除事务id大于当前事务id的记录。

## 9. 你司采用什么隔离级别？为什么

读已提交。InnoDB的默认隔离级别是可重复读，原因是老版本的mysql，用于主从同步的bin log没有row模式，只有statement模式，即记录所有的写相关语句，在读已提交隔离级别下，有数据不一致的风险。而新版本5.0之后的row模式，会记录每行数据实际的变更，已经没有这个问题，读已提交的两次读事务之间如果有别的事务修改数据并成功，在大部分业务场景下是可以接受的。

另外，读已提交的并发性能比可重复读更好。

row模式：记录的是修改前的数据和修改后的数据本身，把从库的数据写成修改后的数据。不执行具体的原SQL语句。

statement模式：记录执行增删改SQL语句本身，从库读取就是原样执行一遍，但同样的sql语句在主库从库执行的结果可能不一致。

## 10. 如何保证多级缓存的数据一致性

消息队列+延迟双删+本地缓存设置较短过期时间 策略。

延迟双删：采用更新数据库，删除缓存后延迟一定时间后再删一次缓存的方式，以防止并发请求导致的脏数据再次写入缓存的问题。

消息队列：数据库更新时，往消息队列放入一条“缓存失效”的消息，消费消息后，删除redis缓存或本地缓存。通过订阅数据库的binlog来获取数据库的更新信息。Canal是一个订阅组件。

一般情况下延迟双删+本地缓存设置较短过期时间就够了。

对实时一致性要求更高，就上消息队列。

## 11. 如何排查慢SQL

开启慢SQL日志slow_query_log， 使用explain分析慢sql原因，主要看type字段，索引的命中情况。

## 12.mysql主从复制的原理

主库会将数据更改写入binlog，从库的IO线程会自动从主库中读binlog放入中继日志relay log中，然后从relay log中同步数据库写入从库。

**主从复制的模式**：

异步复制：不需要从库的响应

半同步复制：需要一个从库的响应

## 13. InnoDB的崩溃恢复机制

E:\工作相关文档\1111跳槽\222跳槽

# 消息队列

## 1. 消息队列的作用

1. 任务异步处理
2. 应用程序解耦
3. 大数据日志收集

## 2. RocketMQ特性

1. 支持事务消息
2. 支持延迟消息
3. 支持指定次数和时间间隔的失败消息重发

## 3. kafka和rabbitMQ的对比 

Kafka和RabbitMQ是两种不同的消息队列系统，它们各自有不同的特点和适用场景。

自己总结：

高性能和高吞吐量：Kafka在吞吐量上性能更优，而RabbitMQ更适合低延迟、高可靠的消息传输。

消息模型和路由机制：Kafka专注于发布/订阅这样的消息模型。而RabbitMQ则有点对点、发布/订阅、消息路由多种消息模型。在路由机制上，RabbitMQ相对来说更灵活，支持更复杂的业务场景。

持久性：RabbitMQ对持久性的支持更全面

扩展性：Kafka对扩展性的支持更好，如果追求高容量，选Kafka

部署和社区生态：RabbitMQ的部署和维护更简单一些。



### Kafka

**特点**：

1. **高吞吐量**：Kafka设计用于处理高吞吐量的数据流，适合大数据处理场景。
2. **分布式系统**：Kafka具有分布式架构，支持数据的水平扩展。
3. **持久性和可靠性**：提供了数据持久化和副本机制，确保消息不会丢失。
4. **发布/订阅模型**：Kafka主要用于发布/订阅场景，它使用主题进行消息分发。
5. **流处理能力**：Kafka不仅提供消息队列功能，还能进行实时数据流处理。

**适用场景**：
- 大数据实时分析，如用户行为日志分析。
- 实时监控和事件驱动架构。
- 日志收集和传输。

### RabbitMQ

**特点**：
1. **可靠性**：提供了多种消息确认机制，确保消息可靠传递。
2. **灵活的消息路由**：支持多种消息模型，包括点对点、发布/订阅和消息路由等。
3. **丰富的插件系统**：可以通过插件实现功能扩展。
4. **易用性**：安装和配置相对简单，易于上手。
5. **支持多种语言**：提供了广泛的客户端库支持。

**适用场景**：
- 需要可靠消息传递的业务场景，如金融支付和订单处理。
- 需要灵活性和复杂路由规则的系统。
- 任务队列和异步处理。

### 对比分析

- **性能和吞吐量**：Kafka在处理大规模数据流和高吞吐量方面具有优势，而RabbitMQ更适用于低延迟、可靠性的消息传递。
- **消息模型和路由**：RabbitMQ提供了更丰富的消息模型和灵活的路由机制，Kafka则更专注于发布/订阅模型。
- **持久性和可靠性**：两者都提供了持久化存储和消息确认机制，但RabbitMQ对消息的持久化支持更全面。
- **可扩展性和部署架构**：Kafka的分布式架构使其能够处理大规模数据流和高并发，而RabbitMQ虽然也支持集群部署，但在处理大量数据流方面相对较弱。
- **社区和生态系统**：Kafka在大数据和流处理领域有广泛应用，RabbitMQ在企业级应用和任务队列领域有成熟的集成解决方案。

在选择Kafka还是RabbitMQ时，应根据具体的业务需求、技术栈和团队经验进行综合考虑。







# Redis

## 1. 为什么redis比较快

1. 纯内存操作。读写速度非常快
2. 单线程。避免了线程上下文切换的开销和锁竞争等问题。（Redis 6.0 之后引入了多线程，但**这只是为了处理网络 I/O**。这让 Redis 在应对海量网络连接时，能利用多核来分担网络读写的压力，而最关键的数据操作部分依然保留了单线程的简单性和无锁优势。）
3. IO多路复用，NIO，同步非阻塞式IO。可以在等待处理请求通知的过程中（selector轮询器轮询到了请求会通知处理请求），做其他事情，提高了系统的吞吐量。
4. 高效的数据结构。提供了哈希表、有序集合等，能够快速进行增删查改，排序。
5. 高效的持久化机制。AOF、RDB或者混用，不影响性能的情况下保证数据安全

## 2. redis如何保证数据不丢失

1. redis持久化，RDB或者AOF。
2. redis集群。例如主从集群，分片集群。

## 3. RDB和AOF有什么区别

它们是redis的两个持久化机制。

1. 机制不同。RDB是通过快照，将某个时间点的完整数据以二进制文件的方式持久化到硬盘中。AOF是将所有写相关的命令追加写到AOF文件中。
2. 文件大小不同。RDB更小。AOF要存所有写命令，会比较大
3. 安全性不同。AOF更安全，宕机RDB有可能丢失最后一次快照的数据
4. 恢复速度不同。RDB恢复更快，AOF要一条条执行命令

## 4. redis的过期删除策略

1. 定时扫描删除。默认每秒10次随机抽取部分设置了过期时间的键，看是否超时并删除。为了不影响redis正常功能，这个扫描时间有上限，默认为25ms。
2. 懒汉式删除。get的时候看是否过时并删除。

## 5. redis的淘汰策略

redis内存如果被用完了，会按过期策略淘汰某些键。

1. allkeys-lru。least recenly use，所有键值中，最长时间没有被使用的
2. volatile-lru。设置了过期时间的键值中，最长时间没有被使用的
3. allkeys-lfu。least frequency use。所有键值中，最少被使用的
4. volatile-lfu。设置了过期时间的键值中，最少被使用的
5. volatile-ttl。淘汰更早过期的键值
6. allkeys-random。
7. volatile-random。
8. no-eviction。不淘汰任何，插入报错。默认是这个。

## 6. redis可以实现哪些功能？

1. 利用原子操作（incr、decr、getset）实现计数器或者sorted set实现排行榜。

2. 利用发布订阅机制或list数据结构实现消息队列。使用subscribe和publish指令可以实现，与rabbitMQ相比，不能确保消息送达，通信速度更快。或者利用List双向队列的先进先出实现，生产者从尾部插入，消费者从头部消费，List可以实现有序的消息传输，相当于Kafka的单partition。

3. 利用setnx实现分布式锁。

   **实现方式**

   先setnx获取锁，如果获取锁成功，再expire设置锁的有效期，并处理业务逻辑，处理完成后，del删除即释放锁。（详细见**分布式**1中此方式的详细内容）

4. 用作缓存，缓解数据库访问压力。

5. 分布式会话管理

## 7. redis有哪些数据类型

1. String。用作缓存时经常用到。或存session信息。用于存整数，incr加一，decr减一。
2. List。底层是双向链表和压缩链表。实现简单的消息队列、存列表数据。
3. Hash。底层是hash表和压缩链表。有时候用于存map，<key, trxObjId, classResult>，或者用于存对象。
4. Set。底层是hash表和整形数组。不重复的特性比如用于实现关注功能，存储我关注的人和关注我的人。
5. Sorted set。数据比较少时底层是压缩链表，数据比较多时是跳跃表。排行榜功能或其他任意需要排序的功能。

## 8. RedLock有什么问题

不建议使用，建议使用普通锁RLock。

1. 性能问题。需要大于一半的结点加锁成功后才能成功，耗时。
2. 并发不安全问题。因为遇到GC可能会加锁失败，但认为加锁成功，导致并发安全问题。

## 9. 缓存雪崩、缓存击穿、缓存穿透是什么，如何解决

**缓存雪崩**

指的是大量键值同时过期，导致请求打到后端服务或者数据库，导致系统压力过大，性能下降或者崩溃。

解决方式：给键值设置随机过期时间，避免大量同时过期。

**缓存击穿**

1. 恶意大量请求缓存中不存在的数据
2. 高并发请求下有大量请求缓存中不存在的数据。

解决方式：

1. 使用布隆过滤器，快速判断缓存中是否存在。
2. 采用熔断策略（兜底）。请求未命中返回兜底结果或失败结果。

**缓存穿透**

热点键过期时，恰巧有大量请求到来，穿透到后端服务或者数据库。

解决方式：

过期不可避免，可以使用分布式锁，使过期时只有一个线程穿透到后端服务或者数据库，其他线程等待结果并从缓存中获得请求数据。

## 10. 什么是布隆过滤器，如何实现

它是一种占用空间小的概率数据结构，用于查询一个数据在集合中是否存在。由位数组和多个哈希函数构成。

对于某个key，如果位数组上各个位置的hash值都是1，那么该key可能存在，否则，一定不存在。

作用：倾向于过滤一定不存在的数据。

1. 比如redis的请求判断，恶意请求过滤，如果不存在直接返回，不再穿透到后端服务或者数据库。
2. 大数据量插入数据去重，避免重复插入。

实现：安装插件，BF.RESERVE my_bloom_filter 0.01 10000创建布隆过滤器，BF.ADD my_bloom_filter key_xx添加key，BF.EXISTS my_bloom_filter查询key是否存在。

## 11. 如何保证本地缓存的数据一致性？为什么有redis了还要本地缓存

1. 如果对一致性要求不是太高，并且并发量不大，设置本地缓存短时过期。、

2. 如果一致性要求高，并且并发很大，可以借助中间件进行数据变更的消息推送，并及时更新本地缓存。

3. 如果并发比较大，一致性要求折中，可以借助Caffeine的自动更新功能。

   

1. 本地缓存没有网络IO，更快，能更好地应对短时高频请求。
2. 使用的本地内存，不依赖外部服务器是否正常运行。



## 12. Rediss实现延迟队列

1. 通过Sorted set实现。使用zrangebyscore（key，score，value）指令获取某个score范围内(时间范围)的有序的消息集合，这个集合就是要处理的延迟消息集合。
2. 使用redisson实现。redisson自带RDelayQueue延迟队列，可以向延迟队列中添加某个延迟时间的任务，并启定时程序隔固定时间监听这个队列，并处理到时的任务。

## 13. 什么是redis脑裂？

主从集群中，sentiniel哨兵结点，由于网络问题，监听不到主节点了，以为主结点挂掉了，并重新选主，实际只是哨兵结点检测不到主结点，主结点还正常，此时就会产生两个主结点，如果客户端还向旧的主结点写数据，就会有安全问题。这就是脑裂。

可以通过两项配置尽量避免脑裂：

1. 设置主结点的从节点数量必须大于配置值，比如1/2，否则禁止写入
2. 设置从结点到主结点的ack时间必须小于配置值，否则禁止写入主结点

## 14. 大key和热key的问题

大key：数据操作会阻塞线程，延时。

热key：倾斜到单台redis服务器上，负载不均，单台压力过大、崩溃、延时高。



大key：String、Hash、集合都可以分割存储

热key：利用本地缓存环境热频数据的压力



# 本地缓存

## 1. guava和caffeine的区别

Caffeine是Guava Cache的现代化演进版本。下面是它们的详细对比：

### 1. 历史渊源和关系

- **Guava Cache**：Google Guava库的一部分，2010年左右推出
- **Caffeine**：由Guava Cache的原作者Ben Manes开发，2014年推出，作为Guava Cache的继任者

**关系**：Caffeine重写了Guava Cache，解决了其架构上的局限性，性能大幅提升。

### 2. 性能对比（核心差异）

#### 内存性能和GC优化

```java
// Guava Cache - 基于ConcurrentHashMap，内存占用较大
LoadingCache<String, Object> guavaCache = CacheBuilder.newBuilder()
        .maximumSize(10000)
        .build(new CacheLoader<String, Object>() {
            @Override
            public Object load(String key) {
                return loadFromDB(key);
            }
        });

// Caffeine - 使用自定义数据结构，优化内存布局
LoadingCache<String, Object> caffeineCache = Caffeine.newBuilder()
        .maximumSize(10000)
        .build(key -> loadFromDB(key));
```

**性能差异**：

- **Caffeine**：读性能比Guava快**5-10倍**
- **内存占用**：Caffeine比Guava减少**30-50%**
- **GC压力**：Caffeine显著降低，特别是大缓存场景

### 3. 特性对比表格

| 特性         | Guava Cache           | Caffeine              | 说明                     |
| ------------ | --------------------- | --------------------- | ------------------------ |
| **基础性能** | 基于ConcurrentHashMap | 自定义高性能数据结构  | Caffeine完胜             |
| **淘汰算法** | LRU（最近最少使用）   | W-TinyLFU（现代算法） | Caffeine命中率更高       |
| **过期策略** | 支持                  | 支持更灵活的策略      | 两者都完善               |
| **异步支持** | 有限                  | 完整的异步API         | Caffeine更适合响应式编程 |
| **监控统计** | 需要手动开启          | 内置完善的监控        | Caffeine更友好           |
| **内存优化** | 一般                  | 显著优化              | CaffeineGC友好           |

### 4. 淘汰算法差异（核心优势）

#### Guava Cache - LRU算法

```java
// LRU：基于访问顺序，简单但命中率有限
Cache<String, Object> lruCache = CacheBuilder.newBuilder()
        .maximumSize(1000)
        .build();
```

#### Caffeine - W-TinyLFU算法

```java
// W-TinyLFU：结合LFU和LRU优点，高命中率
Cache<String, Object> tinyLfuCache = Caffeine.newBuilder()
        .maximumSize(1000)
        // 默认就是W-TinyLFU，无需显式配置
        .build();
```

**算法优势**：
- **命中率**：W-TinyLFU比LRU高**10-20%**
- **适应性强**：能更好处理各种访问模式

# 分布式

## 1.  如何实现分布式锁

1. zookeeper

   **zk原生实现分布式锁原理**

   通过创建有序临时节点实现。每次获取锁时判断是不是最小结点，如果是，获取锁成功，如果不是，watcher监听上一个结点（因为有序，即比自己小的结点）。释放锁即删除临时节点。

   **curator客户端框架实现**

   利用zookeeper的客户端curator实现。自定义zk锁模版类，实现Lock接口，重写getLock和unLock方法。

   https://blog.csdn.net/qq_36551991/article/details/106671155

   ```java
   //lockPath是指定zookeeper存储节点路径
   CuratorFramework curatorFramework = CuratorFrameworkFactory.builder()
   									.connectString("zk地址")
       								.....
       								.build();
   InterProcessMutex lock = new InterProcessMutex(curatorFramework, lockPath);
   
   ```

   ```java
   //getLock方法,锁三秒
   lock.acquire(3, TimeUnit.SECONDS);
   ```

   ```java
   //unLock方法
   lock.release();
   ```

   

2. redis原生

   **实现步骤**

   先setnx获取锁，如果获取锁成功，再expire设置锁的有效期，并处理业务逻辑，处理完成后，del删除即释放锁。

   **原生存在的问题，以及对应的方案**

   1. 死锁问题

      先setnx再expire，分两步，不是原子操作，比如setnx后就宕机或者tomcat.shutdown()了，$\textcolor{Orange}{expire没做，del也没做} $,  那么这把锁就是ttl为-1永久的锁，永远不会被释放，也无法被其他线程获取，就会造成死锁。

      **针对服务器shutdown没有设置expire又没有del的解决方式**：

      1. 使用@PreDestroy注解定义解锁方法，方法中执行del，使得tomcat服务器关闭前删除锁。这种方法仍然不能解决突然宕机。

      2. 能够解决突然宕机。setnx放置的value设为过期时间点。如果expire没能设置有效期，然后再次setnx没有获取到锁，即键值已经存在，此时通过get获取键值value，判断当前时间是否已经超过该值，如果超过，通过getset重置键值的同时获取键值，如果此次获取的值和get获取的值相等或者getset的值为空（即在这个过程中锁已经被释放），说明可以获取锁。

         ```java
         	@Value("${lock.timeout}")
             private Long lockTimeout;
         
         	@Scheduled(cron="0 */1 * * * ?")
             public void closeOrderTask(String[] args) {
                 int setnxResult = RedisSharedPoolUtil.setnx("CLOSE_ORDER");
                 if(setnxResult != null && setnxResult == 1){
                     closeOrder("CLOSE_ORDER");
                 }else{
                     String lockValue = RedisSharedPoolUtil.get("CLOSE_ORDER");
                     //说明锁到期，可以获取锁
                     if(lockValue!=null && System.currentTimeMillis() > Long.parseLong(lockValue)){
                         //更新锁并获取键值
                         String getsetResult = RedisSharedPoolUtil.getset("CLOSE_ORDER");
                         if(getsetResult ==null ||(getsetResult!=null && StringUtils.equals(lockValue, getsetResult))){
                             //真正获取到锁,执行关单
                             closeOrder("CLOSE_ORDER");
                         }else{
                             log.error("没有获取到分布式锁");
                         }
                     }else{
                         log.error("没有获取到分布式锁");
                     }
                 }
                 SpringApplication.run(EurekaServerApplication.class, args);
             }
         
             private void closeOrder(String lockKey) {
                 RedisSharedPoolUtil.expire(lockKey, 5);
                 //执行关单
                 orderService.closeOrder();
                 RedisSharedPoolUtil.del(lockKey);
             }
         ```

         

   2. 不可重入

      当前已获取锁的线程再次尝试获取锁会失败

   3. 锁误删

      如果锁过期删除可能删除的不是当前线程锁，而是其他线程的锁。比如业务执行时间比较长，在执行完之前锁已经过期自动删除，但业务执行完后仍然去del(key)，这时删的明显不是自己持有的锁，有可能误删别的线程持有的新锁。

   4. 不可重试

      获取锁失败不会重试

   5. 无法自动续期

      如果锁设置了过期时间，过期时业务还没执行完，这时候不能自动续期，锁被释放，可能被其他线程获得，就有风险。

3. redission

   ```
   RLock rLock = redissonClient.getLock(lockKey);
   rLock.tryLock(waitTimeout, leaseTime, TimeUnit.SECONDS);
   ```

   ```
   private static final ConcurrentMap<String, RedissonLock.ExpirationEntry> EXPIRATION_RENEWAL_MAP = new ConcurrentHashMap();
   
   private void scheduleExpirationRenewal(long threadId) {
       RedissonLock.ExpirationEntry entry = new RedissonLock.ExpirationEntry();
       RedissonLock.ExpirationEntry oldEntry = (RedissonLock.ExpirationEntry)EXPIRATION_RENEWAL_MAP.putIfAbsent(this.getEntryName(), entry);
       if (oldEntry != null) {
           oldEntry.addThreadId(threadId);
       } else {
           entry.addThreadId(threadId);
           this.renewExpiration();
       }
   
   }
   ```

   ```html
   tryLock源码里通过调用tryAcquire加锁，tryAcquire里调用tryAcquireAsync，tryAcquireAsync里涉及scheduleExpirationRenewal，这时一个定时续期任务，就是看门狗。
   ExpirationEntry里放的是<线程id，次数>的一个map
   EXPIRATION_RENEWAL_MAP里放的是<锁名，ExpirationEntry>,即锁和锁对应的线程map。
   看门狗会去找锁对应的ExpirationEntry是否还在并且ExpirationEntry中是否有当前线程。如果都满足才会续约。
   如果unLock过，锁对应的ExpirationEntry就会被删掉，如果宕机了没有unLock再启动，EXPIRATION_RENEWAL_MAP中不会有重启后的新线程id。这两种情况都不会再续约。
   ```

   1. 解决死锁。

      获取锁的同时就可以设置过期时间leaseTime，防止死锁。但不建议，因为设置了leaseTime，看门狗就会失效。最好是不设置leaseTime，在业务执行完后，finally中unLock手动释放锁。同时看门狗也会生效。就算宕机了，unLock没有执行，如果过期时间内程序再启动后，此时redis中的锁还在，但看门狗定时程序已经不在了（程序都重启了，之前创建锁时启动的定时程序肯定没了），redis中的锁30s到期会自动释放（没有看门狗去续期了）。就算看门狗还在，在EXPIRATION_RENEWAL_MAP里也找不到之前的线程id了，也不会再接着续约了。

   2. 解决误删。

      redisson在getLock时会为锁携带当前线程的threadId，当然也只有拥有当前锁的线程能够解锁。

   3. 解决不可重入

      redisson并不是用String存储键值对，而是用hash结构存，即（key，field，value）。field有两个，一个是拥有锁的线程id，value表示重入次数。另一个是放锁的过期时间。

   4. 解决重试。

      如果tryLock时设置了waitTime，在waitTime内如果没获取到锁，就会不断重试。

   5. 解决自动续期

      如果没有设置leaseTime指定过期时间，leaseTime默认值是-1，默认过期时间30s，并且会触发看门狗WatchDog监听当前的锁实例（监听是否执行了unLock），每隔leaseTime/10会进行一次续期，续期即重置过期时间为30s。

# 数据结构

1.  <5>最长回文子串。动态规划。
2. <146>LRU缓存。hashMap+双向链表。其实就等于LinkedHashMap的结构。
3. <>无重复字符的最长子串。滑动窗口。

# 网络

session与Cookie的区别：
		1. session存储数据在服务器端，Cookie在客户端
		2. session没有数据大小限制，Cookie有
		3. session数据安全，Cookie相对于不安全
